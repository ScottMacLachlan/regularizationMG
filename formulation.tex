We consider the solution of discrete ill-posed problems with linear
forward models of the form
\begin{equation}
\label{eq:exact}
A x = b = \btrue + \eta,
\end{equation}
where $A \in \mathbb{R}^{m\times n}$ (with $m \geq n$) is the forward
operator, $\xtrue$ is the ``true'' solution that we look to recover,
$\btrue = A\xtrue$ is the ``true'' data generated by applying $A$
to $\xtrue$, and $\eta$ is an unknown additive white noise vector.  We
assume that both the true solution and noise-free data are unknown, so
that we can only access the problem via the forward operator, $A$, and
the vector, $b$.  We focus on imaging problems, where $x$ and
$\xtrue$ are taken to be the vectorized forms of digital images, and
$A$ has singular values that decay rapidly towards zero, with the
singular vectors corresponding to the largest singular values
representing smooth modes and those corresponding to the smallest
singular values representing high-frequency modes.  Due to the
presence of the noise and the decay of the singular values, na\"ive
solution of the linear system via least squares, as $A^TA x = A^Tb$,
will be contaminated by noise, with the extent of noise corruption
determined by the decay rate of the singular values as well as the
noise level \cite{Hansenbk}.  Moreover, if $\text{rank}(A)< n$, then
even without noise, there is no unique least-squares solution.

To combat the effects of the (near) rank deficiency and noise, it is typical to
compute an approximation to $\xtrue$ by augmenting the least-squares
formulation with a suitable
Tikhonov regularization \cite{Tikhonov} term, giving
\begin{equation}
\label{eq:tikhgeneric}
\min_{x} \| A x - b \|_2^2 + \lambda^2 \| L x \|_2^2
\end{equation}
where $L$ denotes a regularization matrix that is used to enforce an
expectation on the properties of the solution, $x$, and $\lambda$ is a
parameter used to control the ``balance'' in the minimization between
the two terms.  When $x$ is known to be smooth, a common choice of $L$
might be as the discrete gradient operator or discrete
Laplacian.  The proper choice of $\lambda$ is well-known to be a difficult task,
which can only be accomplished by solving
Equation \eqref{eq:tikhgeneric} for many different values of $\lambda$
and comparing the resulting solution set.

In this paper, we focus on the case of edge-preserving regularization
schemes \cite{CRVogel_2002a, Gazzola_etal_2020}, where the operator $L$ is chosen to allow sharp
changes in the values of the solution, $x$, but only when those
changes are deemed to form a ``natural edge'' in the recovered image.
Deciding on whether or not such a jump is an edge is itself a complex
task, particularly without assuming more information on the problem
structure than is preferable in a general-purpose algorithm.  Here, we
follow the \textit{iteratively reweighted norm} (IRN) method, proposed
in \cite{Gorodnitsky_Rao_1992} and further developed in
\cite{Rodriguez_Wohlberg, RARenaut_etal_2017}. Here, a non-quadratic
constraint, such as $\|Lx\|_p^p$ for $p\approx 1$ or the total
variation of $x$, $\mathrm{TV}(x)$, is reformulated as a sequence of
quadratic regularization problems,
\begin{equation}
\label{eq:sequence}
\min_{x} \| A x - b \|_2^2 + \lambda_\ell^2 \| M^{(\ell)} x \|_2^2,
\end{equation}
where $M^{\ell}$ is defined based on $L$ and the approximate solution
of the $(\ell-1)$th problem, and $\lambda_\ell$ is chosen based on
established approaches for the $\ell$th problem.


{\bf TODO April 25, 2019:} Need to revisit setup, so that we have a
sequence of linear systems that arise from ``linearization''(?) of a
nonlinear type problem that is driven as described in the below...
