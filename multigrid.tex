Multigrid methods are optimal solvers for systems arising from the
discretization of elliptic PDEs. As noted before in \eqref{eq:normal}
the second matrix $L^T W^2 L$ corresponds to a variable-coefficient
diffusion operator on a two-dimensional grid. This can be treated
using multigrid. The variable coefficients that pose problems to
geometric multigrid methods can be treated using algebraic multigrid
that selects the coarse grid variables to treat this variability properly.

The first matrix in \eqref{eq:normal} corresponds to the operator that
has to be inverted. Usually, this is an integral operator, that is not
treated properly by algebraic multigrid. As the effective ratio
between the first and the second matrix in the system to be solved
depends on $\lambda$ we base our solver choice on the size of lambda
relative to the size of the singular values of $K^T K$ and $L^T W^2
L$.

For fixed $W$, the problem posed in \eqref{eq:regularized} is considered in 3 regimes:
\begin{enumerate}
\item When $\lambda > C \frac{\sigma(K)}{\sigma{WL}}$, where
  $\sigma(K)$ is the largest singular value of $K$ and $\sigma{WL}$ is
  the largest singular value of $WL$.  In this regime, the
  regularization (diffusive) term is dominant.
\item When $C \frac{\sigma(K)}{\sigma{WL}} > \lambda > c
  \frac{\sigma(K)}{\sigma{WL}}$, for $\mathcal{O}(1)$ constants $c$
  and $C$, the two terms in \eqref{eq:regularized} are {\it in
    balance}.
\item When $\lambda < c \frac{\sigma(K)}{\sigma{WL}}$, the data term
  in \eqref{eq:regularized} is dominant.
\end{enumerate}

In the first two cases, the diffusive term is significant, so the use
of a mulitigrid method is viable. We construct a multigrid method for
the regularized problem \eqref{eq:regularized} by reducing the size of
our solution, only. In terms of the block least-squares formulation
\eqref{eq:block-ls} the coarse grid correction corresponds to finding
a correction in the range of $P$ minimizing
\[
\min_{y_c}\left\| \left[\begin{array}{c} K \\ \lambda
      WL\end{array}\right](\hat{x}+Py_c) - \left[\begin{array}{c} b \\ 0 \end{array}\right]\right\|^2.
\]
Due to the equivalence of the least-squares problem and the solution
of the normal equations \eqref{eq:normal} the coarse-grid solution $y_c$ is then characterized as the solution to
\[
\left(P^TK^TKP + \lambda^2P^TL^TW^2LP\right)y_c =
P^T\left[\begin{array}{c} K \\ \lambda WL\end{array}\right]^T
\left(\left[\begin{array}{c} b \\ 0 \end{array}\right] - \left[\begin{array}{c} K \\ \lambda
      WL\end{array}\right]\hat{x}\right),
\]
where the right-hand side is the restriction of the residual in the
normal equations associated with $\hat{x}$.

The equivalence of the formulations allows to design a multigrid
algorithms for the normal equations \eqref{eq:normal}, and apply it
directly to the sparse matrices in \eqref{eq:regularized}. As $K^TK$
can get dense, this results in a tremendous reduction of compute time,
further efficient implementations of the application of $K$, e.g.,
using fast transformations, can be used directly.

To obtain $P$, only the matrix $A = L^T W^2 L$ is considered. We apply a
standard AMG setup phase to $A$ to create a hierarchy of interpolation
operators, $P$, and coarse-grid operators, $A_c = P^TAP$ (using
Galerkin coarsening).  From these interpolation operators, we also
create the \textit{one-sided} coarse-grid operators $K_c = KP$ and $(WL)_c =
WLP$, at all levels in the multigrid hierarchy. All that remains is to
specify the multigrid relaxation scheme and cycling parameters.  In
all that follows, we consider only multigrid V-cycles, as W-cycles (or
F-cycles) do not appear to be beneficial.

In the diffusion-dominated regime, the solution of
\eqref{eq:regularized} is primarily determined by the diffusive term
and, as such, we propose a multigrid smoother that is appropriate for
this term.  While classical AMG applied to \eqref{eq:normal} would
typically use a Gauss-Seidel relaxation scheme, this is not
appropriate here, since it would require knowledge of the (dense)
lower-triangular part of $K^TK$.  Instead, we use a red-black-ordered
Jacobi iteration, which allows us to make use of efficient
matrix-vector products with $K$ and $WL$ and their transposes.
Following reduction-based multigrid ideas \cite{}, we use only a
single sweep of pre-relaxation, in a CF ordering, first computing
updates to the coarse-grid points, then to those points on the fine
grid that are not directly represented on the coarse grid.  For each
of these sub-sweeps, we compute a full residual of the rectangular
form of the system,
\[
\hat{r} = \left[\begin{array}{c} b \\ 0 \end{array}\right] -
\left[\begin{array}{c} K \\ \lambda WL\end{array}\right]\hat{x}
\]
but then compute a Jacobi-like update at only the points, $j$, under
consideration, as
\[
\hat{x}_j + {\left(\left[\begin{array}{cc} K^T & \lambda
      L^TW\end{array}\right]\hat{r}\right)_j}/{ \left(K^TK +
  \lambda^2L^TW^2L\right)_{jj}}.
\]
We note that this requires computing only part of the matrix-vector
product with $\left[\begin{array}{cc} K^T & \lambda
    L^TW\end{array}\right]$ and the diagonal entries of $K^TK +
\lambda^2L^TW^2L$.  With this approach, a CF sweep of relaxation costs
the same as 3/2 matrix-vector products with the normal equations (when
done implicitly using the sparse matrices $K$ and $WL$).

Numerical experiments below show that this is an efficient relaxation
scheme for the problem, leading to good multigrid convergence, only
for sufficiently large $\lambda$.  In the second case, when the two
terms are more in balance, the multigrid approach can still be
effective, but the CF relaxation scheme is no longer appropriate,
since the diffusion term is not dominant.  Here, to better reflect the
impact of $K$ on the linear system, we use the CG algorithm as a
relaxation scheme, taking five steps of CG on the normal equations
(with no preconditioner).  Probably need some references here about
using CG as a smoother - Wim's papers on Helmholtz + GMRES, Randy Bank
paper, Xuejun Xu cascadic MG paper???...

We note that the interpolation and coarse-grid operators used above do
not depend on $\lambda$ and, thus, can be formed once for each choice
of $W$ and reused for all values of $\lambda$ for which a multigrid
iteration is needed.

When $\lambda$ is small compared to $\frac{\sigma(K)}{\sigma(WL)}$,
then the problem is essentially equivalent to the unregularized
problem $min_x \|Kx-b\|^2$.  In this case, ... Here, we rely on the
fact that the outer (nonlinear) iteration is aiming to choose $W$ so
that the two terms are in balance.  Thus, while it is important to get
a sufficiently accurate solution when $\lambda$ is small to drive the
nonlinear iteration, we are not concerned with getting high levels of
accuracy in this case (since it occurs only early in the outer
(nonlinear) iteration).  In this case, there is little expected
benefit from a coarse-grid correction based on the diffusive term, so
we consider only a simple iteration.  We use unpreconditioned CG on
the normal equations, allowing up to 50 steps.  In practice, this
yields relatively little improvement on using the solution from the
next-largest $\lambda$ value as the initial guess, and the improvement
to be gained decreases as $\lambda$ does.

{\bf Ask Misha if there's something more reasonable to be done in the
  case of smallest values of $\lambda$.}
